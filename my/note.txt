问题：
    1、gt mapping很奇怪？？？不是一一对应的
    2、图对的生成init_graph_pairs中"Generate 140 * 100 val graph pairs"是怎么回事
    3、大图（n>10）的处理   delta graph
============================================================
接下来的工作：
    1、根据每个图对的ged值单独统计其loss，看看在不同ged值下的图对的损失函数
    2、如何分析通过mlp计算出来的节点保留概率的有效性
============================================================
运行注意事项：
GedGNN、myGNN、MyGNN2切换要改的地方
    trainer.py 第602行: prediction, pre_ged, _, = model_out
    trainer.py 第484-行：生成边图信息
============================================================
如果要使用gpu
    trainer.py 第36行参数self.use_gpu改为True
                第38行设备选择看具体空闲GPU
    GedMatrix.py 第140行的x加上.to(d)
    layers.py 第187行
    LRL()     mask.to(self.device)
    Cross()    mask.to(self.device)
    AReg()       batch_1.to(self.device)
    process_batch()    GED_losses.to(self.device)
==============================================================
1、模型的定义
class GedGNN(torch.nn.Module):
    def __init__()：初始化化参数
    def setup_layers(self): 定义layer
    def convolutional_pass(): 定义layer与layer间的连接
    def forward(self, data): 模型向前传播，返回score等信息
2、模型的调用
    I. self.model(data)：调用forward
    II. 计算loss
    III. 向后传播：losses.backward()
    IV. 优化参数：self.optimizer.step()
    V. epoch+1，返回第一步
===============================================================
代码结构
main()
    - trainer = Trainer(args)  # 根据参数初始化训练器，调用init
        - load_data()  # 加载数据(训练集和测试集数据)
            * self.graphs = list[
                # 训练集
                dict{"gid"=图id,"n"=节点数,"m"=边数,"labels"=[每个点的标签],"graph"=[节点对]}
                ...
                # 验证集
                # 测试集
                ...]
            * self.features 为节点one-hot向量
            * self.ged_dict = (id1，id2):((ged_value, ged_nc, ged_in, ged_ie),[best_node_mapping])
            * 例：(0,1):((3,1,1,0,1),[((0,1),(1,0),(2,1))])
        - transfer_data_to_torch()  # 数据格式转化为torch
            * self.edge_index 边索引由self.graphs['graph']得到，添加边的反向对和自环
                tensor([[7, 3, 3, 3, 5, 6, 1, 0, 4, 3, 1, 8, 9, 2, 2, 0, 2, 2, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],
                        [3, 1, 8, 9, 2, 2, 0, 2, 2, 7, 3, 3, 3, 5, 6, 1, 0, 4, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])
            * self.ged是一个n*n的矩阵(n为图的数量)，存放每个图之间的GED值和其相关信息
                self.ged[i][j] = (ged_value, ged_nc, ged_in, ged_ie)
            * self.mapping是一个n*n的矩阵(n为图的数量)，存放每个图之间的最佳匹配矩阵
                mapping[i][j] = [0,1,0,
                                 1,0,0,
                                 0,0,1]
        - gen_delta_graphs()
            *

        - init_graph_pairs()  # 构建训练图对集合
            * self.training_graphs  # 训练图对集合 (420+1)*420/2 等差数列求和
                len([(type, id1, id2),...,]) = 88420
            * self.val_graphs  # 验证图对集合(验证集与训练集随机100个图匹配匹配)  140*100
                len([(type,test_id,[id1, id2,...id100]),...,]) = 140
            * self.testing_graphs  # 测试图对集合1(测试集与训练集随机100个图匹配)  140*100
                同上
            * self.testing2_graphs  # 测试图对集合2(测试集与测试集随机100个图匹配)  140*100
                同上
        - setup_model()  # 根据模型名称设置模型
    for epoch in (start, end):  # 模型训练轮次
        -train.fit()  # 训练
            for batch in all_batches:  # 迭代训练所有batch
                - train.process_batch()
                    for graph_pair in batch:  # 遍历一个批次内所有的图对
                        - pack_graph_pair()  # 为模型准备图对的各种信息
                            * data = dict{
                                "id_1": 训练集中的顺序, "id_2": , 
                                "edge_index_1: G1边索引, "edge_index_2: G2边索引,
                                "features_1": G1的one-hot, "features_2": G2的one-hot,
                                ## MyGNN2独有
                                "lg_node_list_1: G1边图的节点列表（用于图卷积）, "lg_node_list_2: G2边图的节点列表,
                                "lg_features_1": G1边图的节点特征向量, "lg_features_2": G2边图的节点特征向量,
                                "lg_n1": G1边图节点数,"lg_n2": G2边图节点数,
                                "lg_edge_index_mapping_1: G1边图的边映射索引（用于图卷积）, 
                                "lg_edge_index_mapping_2: G2边图的边映射索引,
                                ##
                                "mapping": ground-truth 匹配矩阵,
                                "n1": G1节点数,"n2": G2节点数,
                                "ged": real_ged 真实的GED值,
                                "hb": max(G1节点数, G2节点数) + max(G1边数, G2边数),
                                "target": real_ged/hb,
                                "ta_ged": [各类别图编辑操作数量]做一些运算后的结果,
                                }
                        - self.model(data)  # 调用模型的forword函数，得到预测值
                        - losses =   # 计算损失函数
                    - losses.backward()  # 反向传播
                    - self.optimizer.step()  # 优化
                    - 返回 losses
            - 把训练的结果保存到result.txt
        -trainer.save(epoch + 1) # 保存模型当前参数
        -trainer.score('test') # 测试，计算指标
            - self.model(data)  # 调用模型的forword函数，得到预测值
            - 计算各个指标
            for i in 测试集图id: # 140
                for j in 随机训练集图id: # 100
                    * mse [,,...,]  # score的均方误差 (s-s*)^2
                    * mae [,,...,]  # ged的绝对误差   |g-g*|
                    * pre [,,...,]  # 预测的ged
                    * gt  [,,...,]  # 真实的ged
                    * acc int       # 预测ged等于正确的个数
                    * fea int       # 预测ged大于正确的个数（可行的编辑距离）
                * rho      # 衡量相关性（预测的ged和真实的ged之间），越高越好
                * tau      # 衡量相关性（预测的ged和真实的ged之间），越高越好
                * pk10/20  # 


================================================================
代码结构
main()
    - trainer = Trainer(args)  # 根据参数初始化训练器，调用init
        - load_data()  
        - transfer_data_to_torch()  
        - init_graph_pairs()  
        - setup_model()  # 根据模型名称设置模型
    for epoch in (start, end):
        -train.fit()  # 训练
            for batch in all_batches: 
                - train.process_batch()
                    for graph_pair in batch:  # 遍历一个批次内所有的图对
                        - pack_graph_pair()  # 为模型准备图对数据
                        - self.model(data)  # 调用模型的forword函数，得到预测值
                        - losses =   
                    - losses.backward()
                    - self.optimizer.step()
                    - 返回 losses
            - 把训练的结果保存到result.txt
        -trainer.save(epoch + 1) # 保存模型当前参数
        -trainer.score('test') # 测试，计算指标
            - self.model(data)  # 调用模型的forword函数，得到预测值
            - 计算各个指标
=================================================================



ERIC与GEDGNN的差异：
1、GEDGNN：3层GNN，最后一层的输出没有relu和dropout
    ERIC：4层GNN，每层的输出都进行了relu和dropout
2、ERIC的正则化损失的权重gamma是一个可变参数


AIDS
训练  421*420/2=88410    9w
测试  140*100
------------------------------------------------------------
Linux  1000
训练  601*600/2=180300   18w
测试  200*100
------------------------------------------------------------
IMDB    总数   节点数≤10   节点数＞10
训练图   900    501        399
测试图   300    148        152
验证图   300    \          \
IMDB-small
训练  501  (501+1)*501/2=125751   12w
测试  148  148*100(训练图中的小图)
IMDB-large
训练  900  125751+399*100=165651   16w
测试  300  300*100(训练图中的小图)
IMDB-small和IMDB-large切换  trainer.py 第55行self.gen_delta_graphs()

+-----------------------+-------------+
|       Parameter       |    Value    |
+=======================+=============+
| Abs path              |             | 绝对路径
+-----------------------+-------------+
| Batch size            | 128         | 批大小
+-----------------------+-------------+
| Bins                  | 16          | 相似性评分的区间
+-----------------------+-------------+
| Bottle neck neurons   | 16          | 瓶颈层的神经元数量
+-----------------------+-------------+
| Bottle neck neurons 2 | 8           |
+-----------------------+-------------+
| Bottle neck neurons 3 | 4           |
+-----------------------+-------------+
| Dataset               | AIDS        | 使用的数据集名称
+-----------------------+-------------+
| Demo                  | 1           | 是否使用缩减的数据集以加快训练和测试
+-----------------------+-------------+
| Dropout               | 0.500       | 正则化的丢弃概率
+-----------------------+-------------+
| Epochs                | 1           |
+-----------------------+-------------+
| Filters 1             | 128         | GNN第一层神经元数量
+-----------------------+-------------+
| Filters 2             | 64          |
+-----------------------+-------------+
| Filters 3             | 32          |
+-----------------------+-------------+
| Finetune              | 0           | 是否微调模型
+-----------------------+-------------+
| Graph pair mode       | combine     | 图对生成的方式
+-----------------------+-------------+
| Gtmap                 | 0           | 是否打包ground-truth映射
+-----------------------+-------------+
| Hidden dim            | 16          | 特定模块中权重矩阵的大小，可能用于处理图嵌入
+-----------------------+-------------+
| Histogram             | 0           | 是否使用直方图
+-----------------------+-------------+
| Learning rate         | 0.001       |
+-----------------------+-------------+
| Loss weight           | 1           |
+-----------------------+-------------+
| Model epoch end       | 2           |
+-----------------------+-------------+
| Model epoch start     | 0           |
+-----------------------+-------------+
| Model name            | GedGNN      |
+-----------------------+-------------+
| Model path            | model_save/ |
+-----------------------+-------------+
| Model train           | 1           | 是否训练模型
+-----------------------+-------------+
| Num delta graphs      | 100         | 每个图生成的合成增量图对数量
+-----------------------+-------------+
| Num testing graphs    | 100         | 每个图的测试图对数量
+-----------------------+-------------+
| Postk                 | 1000        | 后处理中寻找k最佳匹配的参数
+-----------------------+-------------+
| Prediction analysis   | 0           | 是否分析预测的偏差
+-----------------------+-------------+
| Result path           | result/     | 结果存放路径
+-----------------------+-------------+
| Target mode           | linear      | 目标生成的方式
+-----------------------+-------------+
| Tensor neurons        | 16          | 张量网络层的神经元数量
+-----------------------+-------------+
| Value                 | 0           | 模型是预测一个值还是映射
+-----------------------+-------------+
| Weight decay          | 0.001       | 优化器的权重衰减因子
+-----------------------+-------------+

检查梯度
    Gradient for convolution_1.eps is not None
    Gradient for convolution_1.nn.0.weight is not None
    Gradient for convolution_1.nn.0.bias is not None
    Gradient for convolution_1.nn.2.weight is not None
    Gradient for convolution_1.nn.2.bias is not None
    Gradient for convolution_1.nn.3.weight is not None
    Gradient for convolution_1.nn.3.bias is not None
    Gradient for convolution_2.eps is not None
    Gradient for convolution_2.nn.0.weight is not None
    Gradient for convolution_2.nn.0.bias is not None
    Gradient for convolution_2.nn.2.weight is not None
    Gradient for convolution_2.nn.2.bias is not None
    Gradient for convolution_2.nn.3.weight is not None
    Gradient for convolution_2.nn.3.bias is not None
    Gradient for convolution_3.eps is not None
    Gradient for convolution_3.nn.0.weight is not None
    Gradient for convolution_3.nn.0.bias is not None
    Gradient for convolution_3.nn.2.weight is not None
    Gradient for convolution_3.nn.2.bias is not None
    Gradient for convolution_3.nn.3.weight is not None
    Gradient for convolution_3.nn.3.bias is not None
    Gradient for mapMatrix.weight_matrix is not None
    Gradient for mapMatrix.mlp.0.weight is not None
    Gradient for mapMatrix.mlp.0.bias is not None
    Gradient for mapMatrix.mlp.2.weight is not None
    Gradient for mapMatrix.mlp.2.bias is not None
    Gradient for mapMatrix.mlp.4.weight is not None
    Gradient for mapMatrix.mlp.4.bias is not None
    No gradient for lg_mapMatrix.weight_matrix
    No gradient for lg_mapMatrix.mlp.0.weight
    No gradient for lg_mapMatrix.mlp.0.bias
    No gradient for lg_mapMatrix.mlp.2.weight
    No gradient for lg_mapMatrix.mlp.2.bias
    No gradient for lg_mapMatrix.mlp.4.weight
    No gradient for lg_mapMatrix.mlp.4.bias
    No gradient for costMatrix.weight_matrix
    No gradient for costMatrix.mlp.0.weight
    No gradient for costMatrix.mlp.0.bias
    No gradient for costMatrix.mlp.2.weight
    No gradient for costMatrix.mlp.2.bias
    No gradient for costMatrix.mlp.4.weight
    No gradient for costMatrix.mlp.4.bias
    Gradient for attention.weight_matrix is not None
    Gradient for tensor_network.weight_matrix is not None
    Gradient for tensor_network.weight_matrix_block is not None
    Gradient for tensor_network.bias is not None
    Gradient for fully_connected_first.weight is not None
    Gradient for fully_connected_first.bias is not None
    Gradient for fully_connected_second.weight is not None
    Gradient for fully_connected_second.bias is not None
    Gradient for fully_connected_third.weight is not None
    Gradient for fully_connected_third.bias is not None
    Gradient for scoring_layer.weight is not None
    Gradient for scoring_layer.bias is not None
    No gradient for lg_c1.eps
    No gradient for lg_c1.nn.0.weight
    No gradient for lg_c1.nn.0.bias
    No gradient for lg_c1.nn.2.weight
    No gradient for lg_c1.nn.2.bias
    No gradient for lg_c1.nn.3.weight
    No gradient for lg_c1.nn.3.bias
    No gradient for lg_c2.eps
    No gradient for lg_c2.nn.0.weight
    No gradient for lg_c2.nn.0.bias
    No gradient for lg_c2.nn.2.weight
    No gradient for lg_c2.nn.2.bias
    No gradient for lg_c2.nn.3.weight
    No gradient for lg_c2.nn.3.bias
    No gradient for lg_c3.eps
    No gradient for lg_c3.nn.0.weight
    No gradient for lg_c3.nn.0.bias
    No gradient for lg_c3.nn.2.weight
    No gradient for lg_c3.nn.2.bias
    No gradient for lg_c3.nn.3.weight
    No gradient for lg_c3.nn.3.bias
    ----------------------------
    Gradient for convolution_1.eps is not None
    Gradient for convolution_1.nn.0.weight is not None
    Gradient for convolution_1.nn.0.bias is not None
    Gradient for convolution_1.nn.2.weight is not None
    Gradient for convolution_1.nn.2.bias is not None
    Gradient for convolution_1.nn.3.weight is not None
    Gradient for convolution_1.nn.3.bias is not None
    Gradient for convolution_2.eps is not None
    Gradient for convolution_2.nn.0.weight is not None
    Gradient for convolution_2.nn.0.bias is not None
    Gradient for convolution_2.nn.2.weight is not None
    Gradient for convolution_2.nn.2.bias is not None
    Gradient for convolution_2.nn.3.weight is not None
    Gradient for convolution_2.nn.3.bias is not None
    Gradient for convolution_3.eps is not None
    Gradient for convolution_3.nn.0.weight is not None
    Gradient for convolution_3.nn.0.bias is not None
    Gradient for convolution_3.nn.2.weight is not None
    Gradient for convolution_3.nn.2.bias is not None
    Gradient for convolution_3.nn.3.weight is not None
    Gradient for convolution_3.nn.3.bias is not None
    Gradient for mapMatrix.weight_matrix is not None
    Gradient for mapMatrix.mlp.0.weight is not None
    Gradient for mapMatrix.mlp.0.bias is not None
    Gradient for mapMatrix.mlp.2.weight is not None
    Gradient for mapMatrix.mlp.2.bias is not None
    Gradient for mapMatrix.mlp.4.weight is not None
    Gradient for mapMatrix.mlp.4.bias is not None
    Gradient for lg_mapMatrix.weight_matrix is not None
    Gradient for lg_mapMatrix.mlp.0.weight is not None
    Gradient for lg_mapMatrix.mlp.0.bias is not None
    Gradient for lg_mapMatrix.mlp.2.weight is not None
    Gradient for lg_mapMatrix.mlp.2.bias is not None
    Gradient for lg_mapMatrix.mlp.4.weight is not None
    Gradient for lg_mapMatrix.mlp.4.bias is not None
    No gradient for costMatrix.weight_matrix
    No gradient for costMatrix.mlp.0.weight
    No gradient for costMatrix.mlp.0.bias
    No gradient for costMatrix.mlp.2.weight
    No gradient for costMatrix.mlp.2.bias
    No gradient for costMatrix.mlp.4.weight
    No gradient for costMatrix.mlp.4.bias
    Gradient for attention.weight_matrix is not None
    Gradient for tensor_network.weight_matrix is not None
    Gradient for tensor_network.weight_matrix_block is not None
    Gradient for tensor_network.bias is not None
    Gradient for fully_connected_first.weight is not None
    Gradient for fully_connected_first.bias is not None
    Gradient for fully_connected_second.weight is not None
    Gradient for fully_connected_second.bias is not None
    Gradient for fully_connected_third.weight is not None
    Gradient for fully_connected_third.bias is not None
    Gradient for scoring_layer.weight is not None
    Gradient for scoring_layer.bias is not None
    Gradient for lg_c1.eps is not None
    Gradient for lg_c1.nn.0.weight is not None
    Gradient for lg_c1.nn.0.bias is not None
    Gradient for lg_c1.nn.2.weight is not None
    Gradient for lg_c1.nn.2.bias is not None
    Gradient for lg_c1.nn.3.weight is not None
    Gradient for lg_c1.nn.3.bias is not None
    Gradient for lg_c2.eps is not None
    Gradient for lg_c2.nn.0.weight is not None
    Gradient for lg_c2.nn.0.bias is not None
    Gradient for lg_c2.nn.2.weight is not None
    Gradient for lg_c2.nn.2.bias is not None
    Gradient for lg_c2.nn.3.weight is not None
    Gradient for lg_c2.nn.3.bias is not None
    Gradient for lg_c3.eps is not None
    Gradient for lg_c3.nn.0.weight is not None
    Gradient for lg_c3.nn.0.bias is not None
    Gradient for lg_c3.nn.2.weight is not None
    Gradient for lg_c3.nn.2.bias is not None
    Gradient for lg_c3.nn.3.weight is not None
    Gradient for lg_c3.nn.3.bias is not None

A_match和ground-truth
    tensor([[-0.0135, -0.0401, -0.0744, -0.1335, -0.0971, -0.1471, -0.1341, -0.0956,
            -0.0505, -0.0611],
            [ 0.0861,  0.2127, -0.1659,  0.0692,  0.0344, -0.0732, -0.1261, -0.0905,
            -0.0975, -0.0871],
            [ 0.0480, -0.0923,  0.1004, -0.0840, -0.1448,  0.0025, -0.1069,  0.0338,
            -0.1353, -0.0632],
            [ 0.2487,  0.1538, -0.0591, -0.0453, -0.0742, -0.0208,  0.1028, -0.0459,
            -0.1123, -0.1066],
            [ 0.0952,  0.1695, -0.1054, -0.0460, -0.0815, -0.0112, -0.1623, -0.0712,
            -0.0817, -0.0868],
            [ 0.0377, -0.0939, -0.0152, -0.1626, -0.0970,  0.2163,  0.0956,  0.1252,
            -0.1836, -0.1386],
            [ 0.1143,  0.1129, -0.0977, -0.1068,  0.2247, -0.1483, -0.0716, -0.1229,
            0.1497,  0.0245],
            [ 0.0344,  0.0847, -0.0825, -0.0417,  0.4002,  0.0242, -0.0487, -0.0803,
            -0.0642, -0.0018],
            [ 0.0199, -0.0490,  0.0167, -0.1160,  0.0492, -0.0381,  0.1081, -0.0741,
            -0.0949, -0.0488],
            [ 0.0046, -0.0191, -0.0563, -0.0503,  0.1902,  0.0367,  0.0331,  0.0193,
            -0.1176, -0.0812]], grad_fn=<ViewBackward0>)
    tensor([[1., 0., 1., 0., 0., 1., 1., 0., 0., 1.],
            [0., 1., 0., 0., 0., 1., 1., 1., 1., 0.],
            [1., 0., 1., 1., 0., 0., 0., 0., 1., 0.],
            [1., 0., 0., 1., 1., 1., 1., 1., 0., 0.],
            [0., 0., 0., 1., 0., 1., 1., 1., 1., 1.],
            [0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],
            [0., 0., 1., 0., 0., 0., 0., 1., 1., 1.],
            [1., 0., 0., 1., 0., 1., 0., 1., 1., 1.],
            [1., 0., 0., 1., 0., 1., 1., 1., 1., 0.],
            [0., 1., 0., 0., 1., 1., 1., 1., 0., 0.]])

原本的A_cost和用欧式距离计算的A_cost（三组图对的结果）
    tensor([[-0.0684, -0.1926, -0.1419, -0.1354, -0.1613, -0.1110, -0.2584, -0.1108,
            -0.2479, -0.1103],
            [-0.1050, -0.0321, -0.0826, -0.1276, -0.1727, -0.0784, -0.1449, -0.0993,
            -0.1936, -0.2246],
            [-0.0379, -0.0974, -0.1357, -0.0880, -0.1884, -0.1516, -0.1988, -0.1340,
            -0.2411, -0.1403],
            [-0.1231, -0.1836, -0.1557, -0.1783, -0.1020, -0.1143, -0.2887, -0.1374,
            -0.1737, -0.0432],
            [-0.1767, -0.0988, -0.1251, -0.0104, -0.1951, -0.0430, -0.0487, -0.2006,
            -0.1692, -0.1942],
            [-0.1092, -0.1139, -0.1416, -0.0379, -0.1625, -0.1575, -0.1745, -0.1150,
            -0.1884, -0.1829],
            [-0.3187, -0.3073, -0.1620, -0.1756, -0.1914, -0.1604, -0.0014, -0.1843,
            -0.0639, -0.0724],
            [-0.1596, -0.1951, -0.1572, -0.1767, -0.1180, -0.1890, -0.1625, -0.1187,
            -0.1279, -0.1222],
            [-0.2261, -0.2205, -0.2129, -0.3145, -0.1915, -0.1537, -0.0714, -0.0610,
            0.1152, -0.1514],
            [-0.1702, -0.1989, -0.1183, -0.1157, -0.0561, -0.0950, -0.1619, -0.1091,
            -0.2020, -0.2501]], grad_fn=<ViewBackward0>)
    tensor([[0.8332, 1.0000, 0.5754, 0.9863, 0.4687, 0.5934, 0.6560, 0.3201, 0.7390,
            0.1940],
            [0.4384, 0.5711, 0.2497, 0.5756, 0.4941, 0.0000, 0.3279, 0.0393, 0.6334,
            0.4710],
            [0.6489, 0.7347, 0.4083, 0.6079, 0.2669, 0.5629, 0.4453, 0.3997, 0.5314,
            0.2715],
            [0.6968, 0.8893, 0.4100, 0.7971, 0.4609, 0.3428, 0.4412, 0.0996, 0.5626,
            0.1558],
            [0.4692, 0.6789, 0.5251, 0.7132, 0.8978, 0.3377, 0.2971, 0.5874, 0.6271,
            0.9648],
            [0.6333, 0.6452, 0.3091, 0.3506, 0.3177, 0.3529, 0.3269, 0.2867, 0.5097,
            0.4369],
            [0.2377, 0.2362, 0.8249, 0.6708, 0.9778, 0.7905, 0.6224, 0.8833, 0.5631,
            0.9200],
            [0.3329, 0.2605, 0.3975, 0.1130, 0.5165, 0.2031, 0.3338, 0.2498, 0.5522,
            0.5883],
            [0.2863, 0.1743, 0.7682, 0.7100, 0.6850, 0.8967, 0.8761, 0.8712, 0.7781,
            0.8136],
            [0.8445, 0.8092, 0.4073, 0.3076, 0.6186, 0.2302, 0.3787, 0.2367, 0.6958,
            0.7182]], grad_fn=<DivBackward0>)
    ----------------------------------------------------------------------------
    tensor([[-0.1570, -0.1355, -0.1157, -0.0420, -0.2125, -0.1055, -0.1957, -0.1075,
            -0.1846, -0.1335],
            [-0.2612, -0.3109, -0.0745, -0.2204, -0.0555, -0.0599, -0.1258, -0.0408,
            -0.1460, -0.1651],
            [-0.1444, -0.1532, -0.0760, -0.1167, -0.1885,  0.0202, -0.1561, -0.1200,
            -0.1083, -0.1484],
            [-0.1373, -0.2101, -0.0958, -0.1409, -0.1865, -0.1534, -0.1547, -0.1674,
            -0.1087, -0.1195],
            [-0.0830, -0.1528, -0.0831, -0.1109, -0.1021, -0.1111, -0.1514, -0.0869,
            -0.1371, -0.1828],
            [-0.2479, -0.1472, -0.0706, -0.1899, -0.0908, -0.0811, -0.0719, -0.1189,
            -0.1602, -0.0952],
            [-0.1626, -0.1092, -0.1042, -0.1059, -0.1035, -0.1551, -0.0844, -0.1597,
            -0.1217, -0.1122],
            [-0.1324, -0.1722, -0.1188, -0.2113, -0.1057, -0.1043, -0.1791, -0.2392,
            -0.1137, -0.1637],
            [-0.1713, -0.1497, -0.1715, -0.1704, -0.2119, -0.0918, -0.1241, -0.1152,
            -0.1253, -0.1201]], grad_fn=<ViewBackward0>)
    tensor([[0.8779, 0.6795, 0.5713, 0.5973, 0.4063, 0.6810, 0.5222, 0.4428, 0.5794,
            0.6138],
            [0.7788, 0.6975, 0.1660, 0.6397, 0.4384, 0.2171, 0.4946, 0.5838, 0.4469,
            0.5243],
            [0.6034, 0.5831, 0.6612, 0.1276, 0.3851, 0.6090, 0.0412, 0.5992, 0.5056,
            0.0000],
            [0.5078, 0.4106, 0.6462, 0.3010, 0.3937, 0.6557, 0.3625, 0.4613, 0.4914,
            0.4276],
            [0.6192, 0.7077, 0.5253, 0.4676, 0.2397, 0.5634, 0.2967, 0.2605, 0.3477,
            0.3185],
            [0.6242, 0.6993, 0.3014, 0.6271, 0.4712, 0.3303, 0.4563, 0.6757, 0.5354,
            0.4785],
            [0.5469, 0.6654, 0.3787, 0.4590, 0.2553, 0.4600, 0.3711, 0.3179, 0.4173,
            0.2319],
            [0.6890, 0.7270, 0.7735, 0.3907, 0.7305, 0.6109, 0.3231, 1.0000, 0.6104,
            0.3310],
            [0.5111, 0.5788, 0.7472, 0.1457, 0.5089, 0.6837, 0.1782, 0.6613, 0.6302,
            0.0387]], grad_fn=<DivBackward0>)
    ----------------------------------------------------------------
    tensor([[-0.1561,  0.0130, -0.1648, -0.2110, -0.0507, -0.1020, -0.1379, -0.2044,
            -0.1524],
            [-0.0974, -0.1194, -0.1245, -0.1893, -0.2046, -0.1630, -0.1649, -0.0158,
            -0.1371]], grad_fn=<ViewBackward0>)
    tensor([[0.6006, 1.0000, 0.2544, 0.2116, 0.5922, 0.6906, 0.1776, 0.3523, 0.4357],
            [0.0000, 0.4651, 0.3747, 0.6693, 0.4465, 0.3926, 0.7756, 0.6278, 0.6207]],
        grad_fn=<DivBackward0>)