gt mapping很奇怪？？？
============================================================
接下来的工作：
1、删点 
2、损失函数
============================================================
如果要使用gpu
trainer.py 第36行参数self.use_gpu改为True
            第38行设备选择看具体空闲GPU
GedMatrix.py 第140行的x加上.to(d)

==============================================================
1、模型的定义
class GedGNN(torch.nn.Module):
    def __init__()：初始化化参数
    def setup_layers(self): 定义layer
    def convolutional_pass(): 定义layer与layer间的连接
    def forward(self, data): 模型向前传播，返回score等信息
2、模型的调用
    I. self.model(data)：调用forward
    II. 计算loss
    III. 向后传播：losses.backward()
    IV. 优化参数：self.optimizer.step()
    V. epoch+1，返回第一步
===============================================================
代码结构
main()
    - trainer = Trainer(args)  # 根据参数初始化训练器，调用init
        - load_data()  # 加载数据(训练集和测试集数据)
            * self.graphs = list[
                # 训练集
                dict{"n"=节点数,"m"=边数,"labels"=[每个点的标签],"graph"=[节点对]}
                ...
                # 测试集
                ...
            ]
            * self.features 为节点one-hot向量
            * self.ged_dict = (id1，id2):((ged_value, ged_nc, ged_in, ged_ie),[best_node_mapping])
            * 例：(0,1):((3,1,1,0,1),[((0,1),(1,0),(2,1))])
        - transfer_data_to_torch()  # 数据格式转化为torch
            * self.edge_index 由self.graphs['graph']得到，并转换成邻接矩阵形式(无向图)
            * self.ged是一个n*n的矩阵(n为图的数量)，存放每个图之间的GED值和其相关信息
                self.ged[i][j] = (ged_value, ged_nc, ged_in, ged_ie)
            * self.mapping是一个n*n的矩阵(n为图的数量)，存放每个图之间的最佳匹配矩阵
                mapping[i][j] = [0,1,0,
                                 1,0,0,
                                 0,0,1]
        - init_graph_pairs()  # 构建训练图对集合
        - setup_model()  # 根据模型名称设置模型
    for epoch in (start, end):  # 模型训练轮次
        -train.fit()  # 训练
            for batch in all_batches:  # 迭代训练所有batch
                - train.process_batch()
                    for graph_pair in batch:  # 遍历一个批次内所有的图对
                        - pack_graph_pair()  # 为模型准备图对数据
                            * data = dict{
                                "id_1": , "id_2": , 
                                "edge_index_1: 图1邻接矩阵, "edge_index_2: 图2邻接矩阵,
                                "features_1": 图1的one-hot,"features_2": 图2的one-hot,
                                "mapping": ground-truth 匹配矩阵,
                                "n1": G1节点数,"n2": G2节点数,
                                "ged": real_ged 真实的GED值,
                                "hb": max(G1节点数, G2节点数) + max(G1边数, G2边数),
                                "target": real_ged/hb,
                                "ta_ged": [各类别图编辑操作数量]做一些运算后的结果,
                                }
                        - self.model(data)  # 调用模型的forword函数，得到预测值
                        - losses =   # 计算损失函数
                    - losses.backward()  # 反向传播
                    - self.optimizer.step()  # 优化
                    - 返回 losses
            - 把训练的结果保存到result.txt
        -trainer.save(epoch + 1) # 保存模型当前参数
        -trainer.score('test') # 测试，计算指标
            - self.model(data)  # 调用模型的forword函数，得到预测值
            - 计算各个指标
================================================================
代码结构
main()
    - trainer = Trainer(args)  # 根据参数初始化训练器，调用init
        - load_data()  
        - transfer_data_to_torch()  
        - init_graph_pairs()  
        - setup_model()  # 根据模型名称设置模型
    for epoch in (start, end):
        -train.fit()  # 训练
            for batch in all_batches: 
                - train.process_batch()
                    for graph_pair in batch:  # 遍历一个批次内所有的图对
                        - pack_graph_pair()  # 为模型准备图对数据
                        - self.model(data)  # 调用模型的forword函数，得到预测值
                        - losses =   
                    - losses.backward()
                    - self.optimizer.step()
                    - 返回 losses
            - 把训练的结果保存到result.txt
        -trainer.save(epoch + 1) # 保存模型当前参数
        -trainer.score('test') # 测试，计算指标
            - self.model(data)  # 调用模型的forword函数，得到预测值
            - 计算各个指标
=================================================================



+-----------------------+-------------+
|       Parameter       |    Value    |
+=======================+=============+
| Abs path              |             | 绝对路径
+-----------------------+-------------+
| Batch size            | 128         | 批大小
+-----------------------+-------------+
| Bins                  | 16          | 相似性评分的区间
+-----------------------+-------------+
| Bottle neck neurons   | 16          | 瓶颈层的神经元数量
+-----------------------+-------------+
| Bottle neck neurons 2 | 8           |
+-----------------------+-------------+
| Bottle neck neurons 3 | 4           |
+-----------------------+-------------+
| Dataset               | AIDS        | 使用的数据集名称
+-----------------------+-------------+
| Demo                  | 1           | 是否使用缩减的数据集以加快训练和测试
+-----------------------+-------------+
| Dropout               | 0.500       | 正则化的丢弃概率
+-----------------------+-------------+
| Epochs                | 1           |
+-----------------------+-------------+
| Filters 1             | 128         | GNN第一层神经元数量
+-----------------------+-------------+
| Filters 2             | 64          |
+-----------------------+-------------+
| Filters 3             | 32          |
+-----------------------+-------------+
| Finetune              | 0           | 是否微调模型
+-----------------------+-------------+
| Graph pair mode       | combine     | 图对生成的方式
+-----------------------+-------------+
| Gtmap                 | 0           | 是否打包ground-truth映射
+-----------------------+-------------+
| Hidden dim            | 16          | 特定模块中权重矩阵的大小，可能用于处理图嵌入
+-----------------------+-------------+
| Histogram             | 0           | 是否使用直方图
+-----------------------+-------------+
| Learning rate         | 0.001       |
+-----------------------+-------------+
| Loss weight           | 1           |
+-----------------------+-------------+
| Model epoch end       | 2           |
+-----------------------+-------------+
| Model epoch start     | 0           |
+-----------------------+-------------+
| Model name            | GedGNN      |
+-----------------------+-------------+
| Model path            | model_save/ |
+-----------------------+-------------+
| Model train           | 1           | 是否训练模型
+-----------------------+-------------+
| Num delta graphs      | 100         | 每个图生成的合成增量图对数量
+-----------------------+-------------+
| Num testing graphs    | 100         | 每个图的测试图对数量
+-----------------------+-------------+
| Postk                 | 1000        | 后处理中寻找k最佳匹配的参数
+-----------------------+-------------+
| Prediction analysis   | 0           | 是否分析预测的偏差
+-----------------------+-------------+
| Result path           | result/     | 结果存放路径
+-----------------------+-------------+
| Target mode           | linear      | 目标生成的方式
+-----------------------+-------------+
| Tensor neurons        | 16          | 张量网络层的神经元数量
+-----------------------+-------------+
| Value                 | 0           | 模型是预测一个值还是映射
+-----------------------+-------------+
| Weight decay          | 0.001       | 优化器的权重衰减因子
+-----------------------+-------------+



tensor([[-0.0135, -0.0401, -0.0744, -0.1335, -0.0971, -0.1471, -0.1341, -0.0956,
         -0.0505, -0.0611],
        [ 0.0861,  0.2127, -0.1659,  0.0692,  0.0344, -0.0732, -0.1261, -0.0905,
         -0.0975, -0.0871],
        [ 0.0480, -0.0923,  0.1004, -0.0840, -0.1448,  0.0025, -0.1069,  0.0338,
         -0.1353, -0.0632],
        [ 0.2487,  0.1538, -0.0591, -0.0453, -0.0742, -0.0208,  0.1028, -0.0459,
         -0.1123, -0.1066],
        [ 0.0952,  0.1695, -0.1054, -0.0460, -0.0815, -0.0112, -0.1623, -0.0712,
         -0.0817, -0.0868],
        [ 0.0377, -0.0939, -0.0152, -0.1626, -0.0970,  0.2163,  0.0956,  0.1252,
         -0.1836, -0.1386],
        [ 0.1143,  0.1129, -0.0977, -0.1068,  0.2247, -0.1483, -0.0716, -0.1229,
          0.1497,  0.0245],
        [ 0.0344,  0.0847, -0.0825, -0.0417,  0.4002,  0.0242, -0.0487, -0.0803,
         -0.0642, -0.0018],
        [ 0.0199, -0.0490,  0.0167, -0.1160,  0.0492, -0.0381,  0.1081, -0.0741,
         -0.0949, -0.0488],
        [ 0.0046, -0.0191, -0.0563, -0.0503,  0.1902,  0.0367,  0.0331,  0.0193,
         -0.1176, -0.0812]], grad_fn=<ViewBackward0>)
tensor([[1., 0., 1., 0., 0., 1., 1., 0., 0., 1.],
        [0., 1., 0., 0., 0., 1., 1., 1., 1., 0.],
        [1., 0., 1., 1., 0., 0., 0., 0., 1., 0.],
        [1., 0., 0., 1., 1., 1., 1., 1., 0., 0.],
        [0., 0., 0., 1., 0., 1., 1., 1., 1., 1.],
        [0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0., 0., 1., 1., 1.],
        [1., 0., 0., 1., 0., 1., 0., 1., 1., 1.],
        [1., 0., 0., 1., 0., 1., 1., 1., 1., 0.],
        [0., 1., 0., 0., 1., 1., 1., 1., 0., 0.]])
